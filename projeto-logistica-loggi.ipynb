{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c8515d",
   "metadata": {
    "id": "KJqp9AANOCtf",
    "papermill": {
     "duration": 0.012561,
     "end_time": "2024-03-19T18:11:40.252327",
     "exception": false,
     "start_time": "2024-03-19T18:11:40.239766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<img src=\"https://raw.githubusercontent.com/andre-marcos-perez/ebac-course-utils/main/media/logo/newebac_logo_black_half.png\" alt=\"ebac-logo\">\n",
    "\n",
    "---\n",
    "\n",
    "# **Módulo** | Análise de Dados: Análise Exploratória de Dados de Logística II\n",
    "Caderno de **Exercícios**<br>\n",
    "Professor [André Perez](https://www.linkedin.com/in/andremarcosperez/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9654683",
   "metadata": {
    "id": "d9jDtUbDOE1-",
    "papermill": {
     "duration": 0.011804,
     "end_time": "2024-03-19T18:11:40.276405",
     "exception": false,
     "start_time": "2024-03-19T18:11:40.264601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Tópicos**\n",
    "\n",
    "<ol type=\"1\">\n",
    "  <li>Manipulação;</li>\n",
    "  <li>Visualização;</li>\n",
    "  <li>Storytelling.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a63fac",
   "metadata": {
    "id": "SmoHgt-lwkpD",
    "papermill": {
     "duration": 0.011687,
     "end_time": "2024-03-19T18:11:40.300207",
     "exception": false,
     "start_time": "2024-03-19T18:11:40.288520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c630c353",
   "metadata": {
    "id": "GABI6OW8OfQ2",
    "papermill": {
     "duration": 0.011579,
     "end_time": "2024-03-19T18:11:40.323749",
     "exception": false,
     "start_time": "2024-03-19T18:11:40.312170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Exercícios**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94b1993",
   "metadata": {
    "id": "muD1vxozykSC",
    "papermill": {
     "duration": 0.011668,
     "end_time": "2024-03-19T18:11:40.347435",
     "exception": false,
     "start_time": "2024-03-19T18:11:40.335767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Este *notebook* deve servir como um guia para **você continuar** a construção da sua própria análise exploratória de dados. Fique a vontate para copiar os códigos da aula mas busque explorar os dados ao máximo. Por fim, publique seu *notebook* no [Kaggle](https://www.kaggle.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1766b75c",
   "metadata": {
    "id": "zMN1Q3jdwoJm",
    "papermill": {
     "duration": 0.012355,
     "end_time": "2024-03-19T18:11:40.371775",
     "exception": false,
     "start_time": "2024-03-19T18:11:40.359420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01755782",
   "metadata": {
    "id": "QRcqbpLpFK5o",
    "papermill": {
     "duration": 0.011579,
     "end_time": "2024-03-19T18:11:40.395471",
     "exception": false,
     "start_time": "2024-03-19T18:11:40.383892",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Análise Exploratória de Dados de Logística**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2a726",
   "metadata": {
    "id": "6-CvdKwqFPiW",
    "papermill": {
     "duration": 0.011553,
     "end_time": "2024-03-19T18:11:40.419883",
     "exception": false,
     "start_time": "2024-03-19T18:11:40.408330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1\\. Contexto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba173a77",
   "metadata": {
    "id": "XRURE1uUFXGw",
    "papermill": {
     "duration": 0.011756,
     "end_time": "2024-03-19T18:11:40.443768",
     "exception": false,
     "start_time": "2024-03-19T18:11:40.432012",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Neste projeto iremos analisar dados de logistica da empresa Loggi. A empresa trabalha com entregas de produtos diversos em todo Brasil.\n",
    "\n",
    "Aqui iremos gerar insights sobre os problemas enfrentados na cidade de Brasil-DF. Problemas como: otimização das rotas de entrega, alocação de entregas nos veículos da frota com capacidade limitada, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9c14dc",
   "metadata": {
    "id": "QxukLHaqFnkU",
    "papermill": {
     "duration": 0.011724,
     "end_time": "2024-03-19T18:11:40.467519",
     "exception": false,
     "start_time": "2024-03-19T18:11:40.455795",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2\\. Pacotes e bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dcb95f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:11:40.493506Z",
     "iopub.status.busy": "2024-03-19T18:11:40.492886Z",
     "iopub.status.idle": "2024-03-19T18:12:17.269227Z",
     "shell.execute_reply": "2024-03-19T18:12:17.268241Z"
    },
    "id": "NhHkAOBUkBYM",
    "outputId": "042d68b4-3e8b-4531-9ca5-c2f8d6de3a30",
    "papermill": {
     "duration": 36.792825,
     "end_time": "2024-03-19T18:12:17.272264",
     "exception": false,
     "start_time": "2024-03-19T18:11:40.479439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: geopandas in /opt/conda/lib/python3.10/site-packages (0.14.3)\r\n",
      "Requirement already satisfied: fiona>=1.8.21 in /opt/conda/lib/python3.10/site-packages (from geopandas) (1.9.5)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from geopandas) (21.3)\r\n",
      "Requirement already satisfied: pandas>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (2.2.0)\r\n",
      "Requirement already satisfied: pyproj>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (3.6.1)\r\n",
      "Requirement already satisfied: shapely>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from geopandas) (1.8.5.post1)\r\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (23.2.0)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (2024.2.2)\r\n",
      "Requirement already satisfied: click~=8.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (8.1.7)\r\n",
      "Requirement already satisfied: click-plugins>=1.0 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.1.1)\r\n",
      "Requirement already satisfied: cligj>=0.5 in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (0.7.2)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (1.16.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from fiona>=1.8.21->geopandas) (69.0.3)\r\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (1.26.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.4.0->geopandas) (2023.4)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->geopandas) (3.1.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad3761e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:12:17.300183Z",
     "iopub.status.busy": "2024-03-19T18:12:17.299751Z",
     "iopub.status.idle": "2024-03-19T18:12:20.498114Z",
     "shell.execute_reply": "2024-03-19T18:12:20.496771Z"
    },
    "id": "VXUEW0VrF7XW",
    "papermill": {
     "duration": 3.216409,
     "end_time": "2024-03-19T18:12:20.501393",
     "exception": false,
     "start_time": "2024-03-19T18:12:17.284984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Todas as bibliotecas usadas\n",
    "\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550ff71e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:12:20.531352Z",
     "iopub.status.busy": "2024-03-19T18:12:20.530719Z",
     "iopub.status.idle": "2024-03-19T18:13:27.275117Z",
     "shell.execute_reply": "2024-03-19T18:13:27.273326Z"
    },
    "id": "vB58Tmcq10EG",
    "papermill": {
     "duration": 66.761982,
     "end_time": "2024-03-19T18:13:27.278128",
     "exception": false,
     "start_time": "2024-03-19T18:12:20.516146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[distrito-federal.zip]\r\n",
      "  End-of-central-directory signature not found.  Either this file is not\r\n",
      "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\r\n",
      "  latter case the central directory and zipfile comment will be found on\r\n",
      "  the last disk(s) of this archive.\r\n",
      "unzip:  cannot find zipfile directory in one of distrito-federal.zip or\r\n",
      "        distrito-federal.zip.zip, and cannot find distrito-federal.zip.ZIP, period.\r\n",
      "cp: cannot stat './maps/LIM_Unidade_Federacao_A.shp': No such file or directory\r\n",
      "cp: cannot stat './maps/LIM_Unidade_Federacao_A.shx': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "# download dos dados usados\n",
    "\n",
    "# Coleta de dados das entregas;\n",
    "!wget -q \"https://raw.githubusercontent.com/andre-marcos-perez/ebac-course-utils/main/dataset/deliveries.json\" -O deliveries.json\n",
    "# Coleta de dados de geolocalização reversa das entregas. Feita localmente devido a quantidade exorbitante de conteúdo para as regras do Nominatin online\n",
    "!wget -q \"https://raw.githubusercontent.com/andre-marcos-perez/ebac-course-utils/main/dataset/deliveries-geodata.csv\" -O deliveries-geodata.csv\n",
    "# Coleta dos dados do mapa do Distrito Federal\n",
    "!wget -q \"https://geoftp.ibge.gov.br/cartas_e_mapas/bases_cartograficas_continuas/bc100/go_df/versao2016/shapefile/bc100_go_df_shp.zip\" -O distrito-federal.zip\n",
    "!unzip -q distrito-federal.zip -d ./maps\n",
    "!cp ./maps/LIM_Unidade_Federacao_A.shp ./distrito-federal.shp\n",
    "!cp ./maps/LIM_Unidade_Federacao_A.shx ./distrito-federal.shx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fd2f05",
   "metadata": {
    "id": "irQxHW1zGkdZ",
    "papermill": {
     "duration": 0.012798,
     "end_time": "2024-03-19T18:13:27.304379",
     "exception": false,
     "start_time": "2024-03-19T18:13:27.291581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3\\. Exploração de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a086e314",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-19T18:13:27.332863Z",
     "iopub.status.busy": "2024-03-19T18:13:27.332405Z",
     "iopub.status.idle": "2024-03-19T18:13:28.003922Z",
     "shell.execute_reply": "2024-03-19T18:13:28.002164Z"
    },
    "id": "lxLj8e0GHAnr",
    "papermill": {
     "duration": 0.688661,
     "end_time": "2024-03-19T18:13:28.006056",
     "exception": true,
     "start_time": "2024-03-19T18:13:27.317395",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# carregando os dados do arquivo em um dicionário Python chamado data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeliveries.json\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 3\u001b[0m   data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# - wrangling da estrutura;\u001b[39;00m\n\u001b[1;32m      6\u001b[0m deliveries_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data) \u001b[38;5;66;03m# Criando um dataframe pandas com os dados json coletos da Loggi\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "# carregando os dados do arquivo em um dicionário Python chamado data\n",
    "with open('deliveries.json', mode='r', encoding='utf8') as file:\n",
    "  data = json.load(file)\n",
    "\n",
    "# - wrangling da estrutura;\n",
    "deliveries_df = pd.DataFrame(data) # Criando um dataframe pandas com os dados json coletos da Loggi\n",
    "\n",
    "# Normalizando os dados da coluna 'origin' que estão em forma de dicionário\n",
    "hub_origin_df = pd.json_normalize(deliveries_df['origin']) # carregando os dados normalizados em um dataframe chamamdo 'hub_origin_df'.\n",
    "deliveries_df = pd.merge(deliveries_df, hub_origin_df, how='right', left_index=True, right_index=True) # Combinando 'hub_origin_df' com o dataframe original\n",
    "deliveries_df = deliveries_df.drop('origin', axis=1) # Removendo a coluna que foi normalizada em outras duas colunas.\n",
    "deliveries_df = deliveries_df[['name', 'region', 'lng', 'lat', 'vehicle_capacity', 'deliveries']] # organizando o dataframe para uma melhor leitura.\n",
    "deliveries_df.rename(columns={'lng': 'hub_lng', 'lat': 'hub_lat'}, inplace=True) # renomeando as novas colunas para melhor leitura.\n",
    "\n",
    "# A coluna 'deliveries' está em formato de lista de dicionários de dicionários. Portanto vamos dar um explode para melhor visualisação\n",
    "deliveries_exploded_df = deliveries_df[['deliveries']].explode('deliveries') # carregando o dataframe explodido na variavel 'deliveries_exploded_df'\n",
    "deliveries_normalized_df = pd.concat([\n",
    "    pd.DataFrame(deliveries_exploded_df['deliveries'].apply(lambda x: x['size'])).rename(columns={'deliveries': 'dlvr_size'}),\n",
    "    pd.DataFrame(deliveries_exploded_df['deliveries'].apply(lambda x: x['point']['lng'])).rename(columns={'deliveries': 'dlvr_lng'}),\n",
    "    pd.DataFrame(deliveries_exploded_df['deliveries'].apply(lambda x: x['point']['lat'])).rename(columns={'deliveries': 'dlvr_lat'})\n",
    "], axis=1) # Normalizando os dados da coluna 'deliveries' do nosso dataframe explodido que estão em forma de dicionários\n",
    "deliveries_df = deliveries_df.drop('deliveries', axis=1) # removendo a coluna original 'deliveries' que já foi explodida e normalizada\n",
    "deliveries_df = pd.merge(deliveries_df, deliveries_normalized_df, how='right', left_index=True, right_index=True) # Combinando o dataframe normalizado com o dataframe original prezervando o index de cada instancia\n",
    "deliveries_df.reset_index(inplace=True, drop=True) # Resetando o indice de cada linha para obtermos o tamanho real do dataframe, ou seja, o número total de entregas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6623ff23",
   "metadata": {
    "id": "BmKmE7vn7D0h",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "Exploração do schema;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a7f467",
   "metadata": {
    "id": "zOkOrQfW7AGI",
    "outputId": "02db329f-e2e5-4675-aff6-0799f80a61b6",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deliveries_df # DataFrame final com todos os dados normalizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69866da3",
   "metadata": {
    "id": "YzFSmSsB7PKN",
    "outputId": "7abc9020-7258-45b5-ee45-eabc1fd4ace4",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deliveries_df.dtypes # Colunas e seus respectivos tipos de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb6460",
   "metadata": {
    "id": "zxHuPN1C7Zka",
    "outputId": "4254ed6e-af25-4007-bb42-c7302c50783b",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deliveries_df.select_dtypes('object').describe().transpose() # Atribudos categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35201cdd",
   "metadata": {
    "id": "U_yRLHAh78Us",
    "outputId": "6d36daa3-2485-44d8-eaf5-4076bd142dde",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deliveries_df.select_dtypes('int64').describe().transpose() # Atribudos numéricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb9ee27",
   "metadata": {
    "id": "wAUIw8k98NsZ",
    "outputId": "6d0435c3-0c33-4416-9d2c-354489db8fe9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deliveries_df.isna().any() # Verificando quais colunas possuem dados faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d934fab",
   "metadata": {
    "id": "98hexQTyJS9I",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 4\\. Manipulação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13c1077",
   "metadata": {
    "id": "DXU4Ee0QJS9Q",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# - enriquecimento;\n",
    "# Geocodificação dos hubs de distribuição\n",
    "hub_df = deliveries_df[['region', 'hub_lng', 'hub_lat']] # Carregando um dataframe chamado 'hub_df' com as colunas de interesse.\n",
    "hub_df = hub_df.drop_duplicates().sort_values(by='region').reset_index(drop=True) # removendo os valores duplicados para obtermos as coordenadas de cada um dos 3 hubs existentes\n",
    "\n",
    "# Configuração do Nominatim seguindo as regras de uma consulta por segundo\n",
    "geolocator = Nominatim(user_agent='ebac_geocoder')\n",
    "geocoder = RateLimiter(geolocator.reverse, min_delay_seconds=1)\n",
    "\n",
    "# Adicionando colunas ao dataframe 'hub_df' com o conteudo de suas coordenadas e geolocalização reversa.\n",
    "hub_df['coordinates'] = hub_df['hub_lat'].astype(str) + ', ' + hub_df['hub_lng'].astype(str) # coluna com as coordenadas geograficas em forma de string\n",
    "hub_df['geodata'] = hub_df['coordinates'].apply(geocoder) # coluna com o conteúdo da geolocalização reversa das coordenadas.\n",
    "\n",
    "# Normalizando a coluna 'geodata' extraindo um novo dataframe com o endereço de cada hub devidademente dividido\n",
    "hub_geodata_df = pd.json_normalize(hub_df['geodata'].apply(lambda x: x.raw))\n",
    "hub_geodata_df.rename(columns={'address.town': 'hub_town', 'address.suburb': 'hub_suburb', 'address.city': 'hub_city'}, inplace=True) # renomeando colunas de interesse para melhor leitura\n",
    "hub_geodata_df['hub_city'] = np.where(hub_geodata_df['hub_city'].notna(), hub_geodata_df['hub_city'], hub_geodata_df['hub_town']) # Trazendo para a coluna 'hub_city' o que tem de duplicado com a coluna 'hub_town', que para esse caso, pode significar a mesma coisa.\n",
    "hub_geodata_df['hub_suburb'] = np.where(hub_geodata_df['hub_suburb'].notna(), hub_geodata_df['hub_suburb'], hub_geodata_df['hub_city']) # Trazendo apra a coluna 'hub_suburb' o que tem de duplicado com a coluna 'hub_city', que para esse caso, pode significar a mesma coisa.\n",
    "hub_geodata_df = hub_geodata_df.drop('hub_town', axis=1) # removendo a coluna 'hub_town' para melhor leitura do endereço\n",
    "\n",
    "# Combinando o dataframe de endereço do hub com o dataframe original das entregas\n",
    "hub_df = pd.merge(hub_df, hub_geodata_df, left_index=True, right_index=True) # Combinando o dataframe de endereço do hub com o dataframe dos hubs de distribuição\n",
    "hub_df = hub_df[['region', 'hub_suburb', 'hub_city']] # organizando o dataframe dos hubs de distribuição formatado para melhor leitura\n",
    "deliveries_df = pd.merge(deliveries_df, hub_df, how='inner', on='region') # Combinando o dataframe de hubs formatado com o dataframe original\n",
    "deliveries_df = deliveries_df[['name', 'region', 'hub_lng', 'hub_lat', 'hub_city', 'hub_suburb', 'vehicle_capacity', 'dlvr_size', 'dlvr_lng', 'dlvr_lat']] # Organizando o dataframe para melhor leitura\n",
    "\n",
    "# - controle de qualidade;\n",
    "# - etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4a9d91",
   "metadata": {
    "id": "n-WTQi_YoZUl",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carregando o arquivo de geolocalização em um dataframe pandas\n",
    "deliveries_geodata_df = pd.read_csv('deliveries-geodata.csv')\n",
    "deliveries_df = pd.merge(deliveries_df,\n",
    "                         deliveries_geodata_df[['delivery_city', 'delivery_suburb']],\n",
    "                         how='inner', left_index=True, right_index=True) # Comninando o dataframe de geodata deliveries com o dataframe orginal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7c3478",
   "metadata": {
    "id": "Lnyhb6goqQoJ",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## **Analisando a qualidade dos dados extraídos até agora.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97124ebd",
   "metadata": {
    "id": "SeGYQ_83qYa_",
    "outputId": "3ab2f5ae-e883-4cf9-85a0-a540fcceab73",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deliveries_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecb93ff",
   "metadata": {
    "id": "Hktf3m6dhMFv",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## **Analisando quais colunas existem valores faltantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec847351",
   "metadata": {
    "id": "uoi5zJURqbyN",
    "outputId": "aedb6a7a-e970-4356-b958-153428bae481",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "deliveries_df.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323bd759",
   "metadata": {
    "id": "w9rTvF3uhXbl",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## **Percentagem de valores faltantes nas cidades de cada entrega**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70cb6be",
   "metadata": {
    "id": "WV7xrClgqguh",
    "outputId": "b3e2b77b-3528-4a50-cc83-0c18351d7a34",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "city_na = 100 * (deliveries_df[\"delivery_city\"].isna().sum() / len(deliveries_df))\n",
    "city_na"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c726e069",
   "metadata": {
    "id": "_um7l7yOhlxx",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## **Percentagem de valores faltantes nos bairros das entregas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce06d9a7",
   "metadata": {
    "id": "FtTabzP2q5Cu",
    "outputId": "ccd56346-acd7-42f7-ac18-c913ae1d703e",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "suburb_na = 100 * (deliveries_df[\"delivery_suburb\"].isna().sum() / len(deliveries_df))\n",
    "suburb_na"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73fca2a",
   "metadata": {
    "id": "rVnCEKnDi4z3",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## **Percentagem de entregas em cada cidade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326dd4d1",
   "metadata": {
    "id": "s-5QpYzijE_K",
    "outputId": "c5840860-c1ce-4645-effe-3f811bed8484",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prop_city = 100 * (deliveries_df[['delivery_city']].value_counts() / len(deliveries_df))\n",
    "prop_city = prop_city.sort_values(ascending=False)\n",
    "prop_city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df23564",
   "metadata": {
    "id": "jZyFPtxoi-0_",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## **Percentagem de entregas em cada bairro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb5879b",
   "metadata": {
    "id": "lKfNtnryjogP",
    "outputId": "983a8fad-a27f-4f01-e13b-080785230efe",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prop_df = deliveries_df[[\"delivery_suburb\"]].value_counts() / len(deliveries_df)\n",
    "prop_df.sort_values(ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaa0bc8",
   "metadata": {
    "id": "3y94ODMTp0d-",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "###    ***Percentagem de entregas por região***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58049045",
   "metadata": {
    "id": "7VvfsclrpgGN",
    "outputId": "53c56f2b-d161-4626-da8b-dfd9b2b4f0f9",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prop_region = 100 * (deliveries_df[['region']].value_counts() / len(deliveries_df))\n",
    "prop_region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe6c44e",
   "metadata": {
    "id": "KSgjP--1JS9R",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## 5\\. Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8e8808",
   "metadata": {
    "id": "ZSEc7v4gk2eh",
    "outputId": "cc79db5d-5f48-4529-c622-1fd94e74f0cf",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# carregando o mapa do Distrito Federal na variavel mapa\n",
    "mapa = geopandas.read_file('distrito-federal.shp')\n",
    "mapa = mapa.loc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb6f74",
   "metadata": {
    "id": "aBKbH1GMlS0_",
    "outputId": "cfb8b3da-abbd-4581-82bb-baa1161eb618",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carregando a posição dos hubs de distribuição no dataframe 'geo_hub_df'\n",
    "hub_df = deliveries_df[['region', 'hub_lng', 'hub_lat']].drop_duplicates().reset_index(drop=True) # Separando as coordenadas geograficas de cada hub\n",
    "geo_hub_df = geopandas.GeoDataFrame(hub_df, geometry=geopandas.points_from_xy(hub_df['hub_lng'], hub_df['hub_lat'])) # adicionando a coluna 'geometry ao dataframe\n",
    "geo_hub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd1291b",
   "metadata": {
    "id": "jonUnoDxmTNY",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Carregando a posição das entregas no dataframe 'geo_deliveries_df'\n",
    "geo_deliveries_df = geopandas.GeoDataFrame(deliveries_df, geometry=geopandas.points_from_xy(deliveries_df['dlvr_lng'], deliveries_df['dlvr_lat']))\n",
    "geo_deliveries_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca7892a",
   "metadata": {
    "id": "KMfTW6iIrtCJ",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Visualização do mapa geral de entregas por região"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc12e806",
   "metadata": {
    "id": "beBTPbfynr8-",
    "outputId": "9b6b0b49-8d96-4d17-ee22-0422c8923354",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# criando um plot vazio para melhor visualização\n",
    "fig, ax = plt.subplots(figsize=(50/2.54, 50/2.54))\n",
    "\n",
    "# mapa do distrito federal\n",
    "mapa.plot(ax=ax, alpha=0.4, color='lightgrey')\n",
    "\n",
    "# marcando cada entrega no mapa, por região\n",
    "geo_deliveries_df.query('region ==  \"df-0\"').plot(ax=ax, markersize=0.5, color='red', label='df-0')\n",
    "geo_deliveries_df.query('region == \"df-1\"').plot(ax=ax, markersize=0.5, color='blue', label='df-1')\n",
    "geo_deliveries_df.query('region == \"df-2\"').plot(ax=ax, markersize=0.5, color='seagreen', label='df-2' )\n",
    "\n",
    "# marcando cada hub no mapa\n",
    "geo_hub_df.plot(ax=ax, markersize=30, marker='H', color='black', label='hub')\n",
    "\n",
    "# configurando as legendas\n",
    "plt.title('Entregas no Distrito Federal por região', fontdict={'fontsize': 20})\n",
    "lgnd = plt.legend(prop={'size': 18})\n",
    "for handle in lgnd.legendHandles:\n",
    "  handle.set_sizes([50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99238f6d",
   "metadata": {
    "id": "XLcP1ra0xsgQ",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Visualização de grafico de entrega por cidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b045be26",
   "metadata": {
    "id": "xwKglPg_xq_o",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criando dataframe com a porcentagem de entrega por cidade\n",
    "prop_city_df = prop_city.to_frame()\n",
    "prop_city_df.rename(columns={0: 'city_percent'}, inplace=True)\n",
    "\n",
    "# criando grafico de proporção de entregas por cidade\n",
    "with sns.axes_style('whitegrid'):\n",
    "  grafico = sns.barplot(data=prop_city_df.head(10), y='delivery_city', x='city_percent', ci=None, palette='dark')\n",
    "  grafico.set(title='proporção de entregas por cidade', xlabel='Cidade', ylabel='Proporção');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2065c3c7",
   "metadata": {
    "id": "DXE-rxLS0cYV",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Visualização de grafico de entrega por região."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3c590c",
   "metadata": {
    "id": "qzHTgZHo0kfk",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Criando dataframe com a porcentagem de entrega por região\n",
    "data = pd.DataFrame(deliveries_df[['region', 'vehicle_capacity']].value_counts(normalize=True)).reset_index()\n",
    "data.rename(columns={0: \"region_percent\"}, inplace=True)\n",
    "\n",
    "# criando grafico de proporção de entregas por região\n",
    "with sns.axes_style('whitegrid'):\n",
    "  grafico = sns.barplot(data=data, x=\"region\", y=\"region_percent\", ci=None, palette=\"pastel\")\n",
    "  grafico.set(title='Proporção de entregas por região', xlabel='Região', ylabel='Proporção');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a4a5b8",
   "metadata": {
    "id": "6y4Az-Zf03r8",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# **6. Insights Finais:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ed0631",
   "metadata": {
    "id": "U6QI199E1ZZ5",
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "De acordo com todas as informações coletadas, podemos perceber que existem 636149 entregas presentes, distribuidas em todo Distrito Federal através de 3 hubs de distribuição.\n",
    "Para uma melhor logistica, podemos considerar a possibilidade da criação de mais hubs de distribuição posicionados estrategicamente. Por exemplo um hub a mais atendendo o que é df-1 e df-2, assim melhorando a rapidez do atendimento nas zonas mais populosas e com melhor poder aquisitivo da do distrito federal. E mais um hub menor, para atender toda a zona rural localizada na região df-0.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 111.915132,
   "end_time": "2024-03-19T18:13:28.942737",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-19T18:11:37.027605",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
